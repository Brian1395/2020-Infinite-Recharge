#!/usr/bin/env python3
#----------------------------------------------------------------------------
# Copyright (c) 2018 FIRST. All Rights Reserved.
# Open Source Software - may be modified and shared by FRC teams. The code
# must be accompanied by the FIRST BSD license file in the root directory of
# the project.
#----------------------------------------------------------------------------

import json
import time
import sys

from cscore import CameraServer, VideoSource, UsbCamera, MjpegServer, CvSink
from networktables import NetworkTablesInstance
import ntcore
import numpy as np
import cv2
import math

image_width = 416
image_height = 240

#   JSON format:
#   {
#       "team": <team number>,
#       "ntmode": <"client" or "server", "client" if unspecified>
#       "cameras": [
#           {
#               "name": <camera name>
#               "path": <path, e.g. "/dev/video0">
#               "pixel format": <"MJPEG", "YUYV", etc>   // optional
#               "width": <video mode width>              // optional
#               "height": <video mode height>            // optional
#               "fps": <video mode fps>                  // optional
#               "brightness": <percentage brightness>    // optional
#               "white balance": <"auto", "hold", value> // optional
#               "exposure": <"auto", "hold", value>      // optional
#               "properties": [                          // optional
#                   {
#                       "name": <property name>
#                       "value": <property value>
#                   }
#               ],
#               "stream": {                              // optional
#                   "properties": [
#                       {
#                           "name": <stream property name>
#                           "value": <stream property value>
#                       }
#                   ]
#               }
#           }
#       ]
#       "switched cameras": [
#           {
#               "name": <virtual camera name>
#               "key": <network table key used for selection>
#               // if NT value is a string, it's treated as a name
#               // if NT value is a double, it's treated as an integer index
#           }
#       ]
#   }

configFile = "/boot/frc.json"

class CameraConfig: pass

team = 3691
server = False
cameraConfigs = []
switchedCameraConfigs = []
cameras = []

class GripPipelinePort:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsl_threshold_hue = [0.0, 180.0]
        self.__hsl_threshold_saturation = [114.65827338129496, 255.0]
        self.__hsl_threshold_luminance = [110.07194244604317, 255.0]

        self.hsl_threshold_output = None

        self.__find_contours_input = self.hsl_threshold_output
        self.__find_contours_external_only = False

        self.find_contours_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSL_Threshold0:
        self.__hsl_threshold_input = source0
        (self.hsl_threshold_output) = self.__hsl_threshold(self.__hsl_threshold_input, self.__hsl_threshold_hue, self.__hsl_threshold_saturation, self.__hsl_threshold_luminance)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsl_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)
        return self.find_contours_output

    @staticmethod
    def __hsl_threshold(input, hue, sat, lum):
        """Segment an image based on hue, saturation, and luminance ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max luminance.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HLS)
        return cv2.inRange(out, (hue[0], lum[0], sat[0]),  (hue[1], lum[1], sat[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        return contours

class GripPipelineCell:
    """
    An OpenCV pipeline generated by GRIP.
    """
    
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsl_threshold_hue = [24.280575539568343, 52.525597269624576]
        self.__hsl_threshold_saturation = [123.83093525179855, 255.0]
        self.__hsl_threshold_luminance = [64.20863309352518, 255.0]

        self.hsl_threshold_output = None

        self.__cv_erode_src = self.hsl_threshold_output
        self.__cv_erode_kernel = None
        self.__cv_erode_anchor = (-1, -1)
        self.__cv_erode_iterations = 3.0
        self.__cv_erode_bordertype = cv2.BORDER_CONSTANT
        self.__cv_erode_bordervalue = (-1)

        self.cv_erode_output = None

        self.__cv_dilate_src = self.cv_erode_output
        self.__cv_dilate_kernel = None
        self.__cv_dilate_anchor = (-1, -1)
        self.__cv_dilate_iterations = 3.0
        self.__cv_dilate_bordertype = cv2.BORDER_CONSTANT
        self.__cv_dilate_bordervalue = (-1)

        self.cv_dilate_output = None

        self.__find_contours_input = self.cv_dilate_output
        self.__find_contours_external_only = False

        self.find_contours_output = None


    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSL_Threshold0:
        self.__hsl_threshold_input = source0
        (self.hsl_threshold_output) = self.__hsl_threshold(self.__hsl_threshold_input, self.__hsl_threshold_hue, self.__hsl_threshold_saturation, self.__hsl_threshold_luminance)

        # Step CV_erode0:
        self.__cv_erode_src = self.hsl_threshold_output
        (self.cv_erode_output) = self.__cv_erode(self.__cv_erode_src, self.__cv_erode_kernel, self.__cv_erode_anchor, self.__cv_erode_iterations, self.__cv_erode_bordertype, self.__cv_erode_bordervalue)

        # Step CV_dilate0:
        self.__cv_dilate_src = self.cv_erode_output
        (self.cv_dilate_output) = self.__cv_dilate(self.__cv_dilate_src, self.__cv_dilate_kernel, self.__cv_dilate_anchor, self.__cv_dilate_iterations, self.__cv_dilate_bordertype, self.__cv_dilate_bordervalue)

        # Step Find_Contours0:
        self.__find_contours_input = self.cv_dilate_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only) #mode = CV_RETR_LIST, method = CV_CHAIN_APPROX_SIMPLE
        return self.cv_dilate_output, self.find_contours_output

    @staticmethod
    def __hsl_threshold(input, hue, sat, lum):
        """Segment an image based on hue, saturation, and luminance ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max luminance.
        Returns:
            A black and white numpy.ndarray.
        """
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HLS)
        return cv2.inRange(out, (hue[0], lum[0], sat[0]),  (hue[1], lum[1], sat[1]))

    @staticmethod
    def __cv_erode(src, kernel, anchor, iterations, border_type, border_value):
        """Expands area of lower value in an image.
        Args:
           src: A numpy.ndarray.
           kernel: The kernel for erosion. A numpy.ndarray.
           iterations: the number of times to erode.
           border_type: Opencv enum that represents a border type.
           border_value: value to be used for a constant border.
        Returns:
            A numpy.ndarray after erosion.
        """
        return cv2.erode(src, kernel, anchor, iterations = (int) (iterations +0.5),
                            borderType = border_type, borderValue = border_value)

    @staticmethod
    def __cv_dilate(src, kernel, anchor, iterations, border_type, border_value):
        """Expands area of higher value in an image.
        Args:
           src: A numpy.ndarray.
           kernel: The kernel for dilation. A numpy.ndarray.
           iterations: the number of times to dilate.
           border_type: Opencv enum that represents a border type.
           border_value: value to be used for a constant border.
        Returns:
            A numpy.ndarray after dilation.
        """
        return cv2.dilate(src, kernel, anchor, iterations = (int) (iterations +0.5),
                            borderType = border_type, borderValue = border_value)

    @staticmethod
    def __find_contours(src, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        contours, hierarchy = cv2.findContours(src, mode=mode, method=method)
        return contours
    
def parseError(str):
    """Report parse error."""
    print("config error in '" + configFile + "': " + str, file=sys.stderr)

def readCameraConfig(config):
    """Read single camera configuration."""
    cam = CameraConfig()

    # name
    try:
        cam.name = config["name"]
    except KeyError:
        parseError("could not read camera name")
        return False

    # path
    try:
        cam.path = config["path"]
    except KeyError:
        parseError("camera '{}': could not read path".format(cam.name))
        return False

    # stream properties
    cam.streamConfig = config.get("stream")

    cam.config = config

    cameraConfigs.append(cam)
    return True

def readSwitchedCameraConfig(config):
    """Read single switched camera configuration."""
    cam = CameraConfig()

    # name
    try:
        cam.name = config["name"]
    except KeyError:
        parseError("could not read switched camera name")
        return False

    # path
    try:
        cam.key = config["key"]
    except KeyError:
        parseError("switched camera '{}': could not read key".format(cam.name))
        return False

    switchedCameraConfigs.append(cam)
    return True

def readConfig():
    """Read configuration file."""
    global team
    global server

    # parse file
    try:
        with open(configFile, "rt", encoding="utf-8") as f:
            j = json.load(f)
    except OSError as err:
        print("could not open '{}': {}".format(configFile, err), file=sys.stderr)
        return False

    # top level must be an object
    if not isinstance(j, dict):
        parseError("must be JSON object")
        return False

    # team number
    try:
        team = j["team"]
    except KeyError:
        parseError("could not read team number")
        return False

    # ntmode (optional)
    if "ntmode" in j:
        str = j["ntmode"]
        if str.lower() == "client":
            server = False
        elif str.lower() == "server":
            server = True
        else:
            parseError("could not understand ntmode value '{}'".format(str))

    # cameras
    try:
        cameras = j["cameras"]
    except KeyError:
        parseError("could not read cameras")
        return False
    for camera in cameras:
        if not readCameraConfig(camera):
            return False

    # switched cameras
    if "switched cameras" in j:
        for camera in j["switched cameras"]:
            if not readSwitchedCameraConfig(camera):
                return False

    return True

def startCamera(config):
    """Start running the camera."""
    print("Starting camera '{}' on {}".format(config.name, config.path))
    inst = CameraServer.getInstance()
    camera = UsbCamera(config.name, config.path)
    server = inst.startAutomaticCapture(camera=camera, return_server=True)

    camera.setConfigJson(json.dumps(config.config))
    camera.setConnectionStrategy(VideoSource.ConnectionStrategy.kKeepOpen)

    if config.streamConfig is not None:
        server.setConfigJson(json.dumps(config.streamConfig))

    return camera, inst, server

def startSwitchedCamera(config):
    """Start running the switched camera."""
    print("Starting switched camera '{}' on {}".format(config.name, config.key))
    server = CameraServer.getInstance().addSwitchedCamera(config.name)

    def listener(fromobj, key, value, isNew):
        if isinstance(value, float):
            i = int(value)
            if i >= 0 and i < len(cameras):
              server.setSource(cameras[i])
        elif isinstance(value, str):
            for i in range(len(cameraConfigs)):
                if value == cameraConfigs[i].name:
                    server.setSource(cameras[i])
                    break

    NetworkTablesInstance.getDefault().getEntry(config.key).addListener(
        listener,
        ntcore.constants.NT_NOTIFY_IMMEDIATE |
        ntcore.constants.NT_NOTIFY_NEW |
        ntcore.constants.NT_NOTIFY_UPDATE)

    return server

if __name__ == "__main__":
    if len(sys.argv) >= 2:
        configFile = sys.argv[1]

    # read configuration
    if not readConfig():
        sys.exit(1)

    # start NetworkTables
    ntinst = NetworkTablesInstance.getDefault()
    if server:
        print("Setting up NetworkTables server")
        ntinst.startServer()
    else:
        print("Setting up NetworkTables client for team {}".format(team))
        ntinst.startClientTeam(team)
        
    sd = ntinst.getTable("Shuffleboard")

    camServers = []
    # start cameras
    for config in cameraConfigs:
        camera, inst, camServer = startCamera(config)
        camServers.append(inst)
        cameras.append(camera)

    # start switched cameras
    for config in switchedCameraConfigs:
        startSwitchedCamera(config)

    img0 = np.zeros(shape=(image_height, image_width, 3), dtype=np.uint8)
    img1 = np.zeros(shape=(image_height, image_width, 3), dtype=np.uint8)

    
    cvSink0 = camServers[0].getVideo() #cv2.VideoCapture(0)#cameras[0].getFrame()#camServers[0].getVideo()
    cvSink1 = camServers[1].getVideo()#cv2.VideoCapture(1)#cameras[1].getFrame()#camServers[1].getVideo()
    outputStream0 = camServers[0].putVideo("stream0", (image_width), (image_height))
    outputStream1 = camServers[1].putVideo("stream1", (image_width), (image_height))
    
    print(cvSink0)
    print(cvSink1)
    # loop forever
    while True:
        timestamp, img0 = cvSink0.grabFrame(img0)
        frame0 = img0.copy()
        timestamp, img1 = cvSink1.grabFrame(img1)
        frame1 = img1.copy()
        contsPort = GripPipelinePort().process(frame0)
        blobs, contsCells = GripPipelineCell().process(frame1)
        #print(blobs)

        
        if(len(contsPort)==1):
            M = cv2.moments(conts[0])
            if(M["m00"] != 0):
                x = int(M["m10"]/M["m00"])
                cx = (x - 80)/80
                
                y = int(M["m01"]/M["m00"])
                cy = (y - 60)/-60

                cv2.line(img0,(x,0),(x,120),(255,255,255),5)
                cv2.putText(img0,"PORT CAM",(70,110),cv2.FONT_HERSHEY_SIMPLEX, .8, (255,255,255),3)
                #cv2.putText(img,str(num),(x-5,y+12),cv2.FONT_HERSHEY_SIMPLEX, .8, (255,255,255),3)

                sd.putNumber("X-Port",cx)
                sd.putNumber("Y-Port",cx)
                
            else:
                print("POWER PORT NOT FOUND")
                sd.putNumber("X-Port",10)
                sd.putNumber("Y-Port",10)
        

        XConts = []
        YConts = []
        AConts = []
        #num = 0

        
        for i in contsCells:
            #num += 1
            M = cv2.moments(i)
            if(M["m00"] != 0):
                x = int(M["m10"]/M["m00"])
                cx = (x - 80)/80
                XConts.append(cx)
                
                y = int(M["m01"]/M["m00"])
                cy = (y - 60)/-60
                YConts.append(cy)

                ar = cv2.contourArea(i)
                AConts.append(ar)
                rad = int(math.sqrt(ar/ 3.14159265))

                cv2.circle(img1,(x,y),rad,(199,190,24),3)
                #cv2.putText(img,str(num),(x-5,y+12),cv2.FONT_HERSHEY_SIMPLEX, .8, (255,255,255),3)
                
            else:
                print("POWER CELL NOT FOUND")
                sd.putNumberArray("X-Ports",[0])
                sd.putNumberArray("Y-Ports",[-1])
                sd.putNumberArray("ContourAreas",[0])
            
                
        sd.putNumberArray("X-Ports",XConts)
        sd.putNumberArray("Y-Ports",YConts)
        sd.putNumberArray("ContourAreas",AConts)

        xTrack = sd.getNumber("TrackedX",10)
        temp = 0
        if(xTrack != 10 and len(XConts) > 0):  
            #yTrack = sd.getNumber("TrackedY",10) 
            xErr = abs(XConts[0] - xTrack)
            #yErr = YConts[0] - yTrack
            for n in XConts:
                xErrT = abs(n - xTrack)
                #yErrT = YConts[int(n)] - yTrack
                if(xErrT < xErr):
                    xErr = xErrT
                    #yErr = yErrT
                    temp = XConts.index(n)
            sd.putNumber("TrackedX", XConts[temp])
            sd.putNumber("TrackedY", YConts[temp])
            cv2.circle(img1,(int((XConts[temp]*80)+80),int((YConts[temp]*-60)+60)),3,(0,0,0),5)#(3,252,123)
        cv2.putText(img1,"CELL CAM",(70,110),cv2.FONT_HERSHEY_SIMPLEX, .8, (255,255,255),3)    

        
        outputStream0.putFrame(img0)
        outputStream1.putFrame(img1)
        time.sleep(.3)
